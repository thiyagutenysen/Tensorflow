{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d823e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5addf5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcb6fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Load text data in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6479d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1E5ZR1Z4OQJG\", \"asin\": \"1495329321\", \"reviewerName\": \"Pure Jonel \\\"Pure Jonel\\\"\", \"helpful\": [0, 0], \"reviewText\": \"Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\", \"overall\": 4.0, \"summary\": \"An amazing first novel\", \"unixReviewTime\": 1396137600, \"reviewTime\": \"03 30, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at the gist of the data\n",
    "with open(\"Books_small.json\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325a8ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW =  Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "SCORE =  4.0\n"
     ]
    }
   ],
   "source": [
    "# convert text to json and get required fields\n",
    "with open(\"Books_small.json\") as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line) # covert text to json format\n",
    "        print(\"REVIEW = \", review[\"reviewText\"])\n",
    "        print(\"SCORE = \", review[\"overall\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe9a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw way of creating training data\n",
    "reviews = []\n",
    "with open(\"Books_small.json\") as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append((review[\"reviewText\"], review[\"overall\"])) # storing data as tuple -> (text, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4083ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Information on the CCRN dose not change that much, so using an outdated book will not effect you too much. I used this and looked up the blue print from AACN. This book is a bit winded, and goes into a lot of detail about anatomy and such that you might not really need to know it pass. If you want to be know all that information, then you are a far more studious nurse then I.  The book is broken up well so you can easily skip this part, and just study the patho. The CD is great! I fell like that helped me a ton!',\n",
       " 4.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve from training data\n",
    "reviews[random.randint(0,999)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8738a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.score >= 4:\n",
    "            return \"POSITIVE\"\n",
    "        elif self.score == 3:\n",
    "            return \"NEUTRAL\"\n",
    "        else:\n",
    "            return \"NEGATIVE\"\n",
    "\n",
    "# Structured way of creating training data\n",
    "reviews = []\n",
    "with open(\"Books_small.json\") as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review[\"reviewText\"], review[\"overall\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0a38dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love it! rock and roll + time travel = Love. I really enjoyed Megan and Davy's built up to romance. I love the twist. Who hasn't dreamed about time travel where you find you true love.I received a copy of this book for a honest review.\n",
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# retrieve from training data\n",
    "# rather than remembering the order of the index in raw data storage, we can access with it's name (text or score) itself in, \n",
    "# structured data storage\n",
    "index = random.randint(0,999)\n",
    "print(reviews[index].text)\n",
    "print(reviews[index].score)\n",
    "print(reviews[index].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1cf757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58130a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05f3663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c041c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax\n",
    "# I pass in list, we can also pass numpy array and pandas dataframe\n",
    "train, test = train_test_split(reviews, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9efb8b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "670\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "print(type(train))\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04dfa2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting x and y manually\n",
    "x_train = [x.text for x in train]\n",
    "y_train = [y.sentiment for y in train]\n",
    "x_test = [x.text for x in test]\n",
    "y_test = [y.sentiment for y in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d9e68e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 670\n",
      "330 330\n",
      "Since I have been on a Sandra Brown reading binge, I got this one from the library and I am certainly glad that I did not buy this one. The story is about a family in a small southern town called Heaven, Louisiana.The heroine is Schyler Crandall who has returned home to Heaven from London, where she escaped to after her sister, Tricia betrays her.  Schyler has come back to the family home named Belle Terre, an old southern home that she loves, because her father has had a major heart attack.  Since her father is in the hospital, Schyler takes on the family business.The book is heavy on very crass language and sex scenes.  If you are looking for a romance novel, then this book is hot what I would call romantic, The romantic involvement for Schyler is a Cajun who lives on the bayou, Cash Boudreaux.  He is as foul mouthed and crude as they come.  How any woman could find anything romantic about this man is beyound me.There are a number of other sex scenes with other characters that I basically skipped over.  I am not a blushing virgin and I have read many romance novels in the past but this one is so crass that I was even appalled.Also for dog lovers, this book has a pit bull fight that I could not read.  Cruelty to animals and to people is another reason that I did not like this book.  Also stereotypes abound about the south in this book that are so overdone as to be silly.&#34;Slow Heat in Heaven&#34; is one of Sandra Brown's earlier novels; I will stick to reading her more current books because they have more appeal to me.  This one barely earns that two stars that I am giving it. NEGATIVE\n",
      "I do not watch the TV show, but this book was recommended to me as a great read and I was not disappointed! POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# validating\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))\n",
    "index = random.randint(0,299)\n",
    "print(x_train[index], y_train[index])\n",
    "print(x_test[index], y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99850130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b39cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4caa584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize each review\n",
    "vectorizer = CountVectorizer() # initialize sklearn vectorizer\n",
    "vectorizer.fit(x_train) # pass in list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6de01727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer is a dictionary of words now, transform will use this dictionary to turn a sentense or para into vector of integers\n",
    "x_train = vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8def844f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(670, 7372)\n",
      "<class 'numpy.ndarray'>\n",
      "  (0, 350)\t2\n",
      "  (0, 539)\t1\n",
      "  (0, 562)\t1\n",
      "  (0, 1148)\t1\n",
      "  (0, 1515)\t1\n",
      "  (0, 1558)\t1\n",
      "  (0, 1800)\t1\n",
      "  (0, 2007)\t1\n",
      "  (0, 2895)\t1\n",
      "  (0, 3054)\t1\n",
      "  (0, 3545)\t1\n",
      "  (0, 5197)\t1\n",
      "  (0, 6475)\t1\n",
      "  (0, 6593)\t1\n",
      "  (0, 6595)\t1\n",
      "  (0, 7086)\t1\n",
      "  (0, 7353)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x7372 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation\n",
    "print(type(x_train))\n",
    "print(x_train.shape)\n",
    "print(type(x_train.toarray())) # convert scipy matrix to numpy array\n",
    "print(x_train[0])\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f2b08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models and classification\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c0b283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test dataset\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c1318ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.9985074626865672\n",
      "Testing Accuracy =  0.8242424242424242\n",
      "Testing F1 Score =  [0.91289199 0.23728814 0.22222222]\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "# Linear SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# C - Inverse of regularization strength, smaller values specify stronger regularization. \n",
    "linear_svm_model = SVC(kernel=\"linear\", C=0.5)\n",
    "linear_svm_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", linear_svm_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", linear_svm_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "# we have to mention average = None bcz we are using multiclass, if y is binary then we don't need to mention average\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, linear_svm_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a2c06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.991044776119403\n",
      "Testing Accuracy =  0.8515151515151516\n",
      "Testing F1 Score =  [0.92561983 0.05128205 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "# RBF SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# C - Inverse of regularization strength, smaller values specify stronger regularization.\n",
    "# gamma - default value is 'scale', we can also give float values\n",
    "rbf_svm_model = SVC(kernel=\"rbf\", C=11, gamma=0.005)\n",
    "rbf_svm_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", rbf_svm_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", rbf_svm_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, rbf_svm_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96536a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.9925373134328358\n",
      "Testing Accuracy =  0.7787878787878788\n",
      "Testing F1 Score =  [0.88214286 0.22222222 0.14285714]\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "# RBF SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# C - Inverse of regularization strength, smaller values specify stronger regularization.\n",
    "# degree - polynomial degree - default is 3\n",
    "poly_svm_model = SVC(kernel=\"poly\", degree=3, C=10000)\n",
    "poly_svm_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", poly_svm_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", poly_svm_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, poly_svm_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8624ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8731343283582089\n",
      "Testing Accuracy =  0.8151515151515152\n",
      "Testing F1 Score =  [0.89864865 0.13333333 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "# Decision Tree \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier(max_depth=5) # default max_depth is None\n",
    "decision_tree_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", decision_tree_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", decision_tree_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, decision_tree_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3df4ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper code\n",
    "# best way to convert scipy sequence to numpy array, don't use np.array(seq), do seq.toarray()\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f76a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.9776119402985075\n",
      "Testing Accuracy =  0.8121212121212121\n",
      "Testing F1 Score =  [0.89678511 0.08510638 0.09090909]\n"
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "# Gaussian Naieve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussian_nb_model = GaussianNB()\n",
    "gaussian_nb_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", gaussian_nb_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", gaussian_nb_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, gaussian_nb_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24aef9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.9985074626865672\n",
      "Testing Accuracy =  0.8303030303030303\n",
      "Testing F1 Score =  [0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# Model 6\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# C - Inverse of regularization strength; must be a positive float, \n",
    "# Like in support vector machines, smaller values specify stronger regularization.\n",
    "logistic_reg_model = LogisticRegression(C=1, max_iter=1000) # default C is 1, max_iter is 100\n",
    "logistic_reg_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", logistic_reg_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", logistic_reg_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, logistic_reg_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00d60089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8686567164179104\n",
      "Testing Accuracy =  0.7636363636363637\n",
      "Testing F1 Score =  [0.87017544 0.07272727 0.11428571]\n"
     ]
    }
   ],
   "source": [
    "# Model 7\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(3) # default neighbor parameter is 5\n",
    "knn_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", knn_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", knn_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, knn_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "343a78e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8253731343283582\n",
      "Testing Accuracy =  0.8575757575757575\n",
      "Testing F1 Score =  [0.9233279 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Model 8\n",
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators - number of trees in the forest - default is 100\n",
    "# max_depth of each tree is None by default\n",
    "random_forest_model = RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "random_forest_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", random_forest_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", random_forest_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, random_forest_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76d7dd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8552238805970149\n",
      "Testing Accuracy =  0.8121212121212121\n",
      "Testing F1 Score =  [0.89761092 0.1509434  0.0952381 ]\n"
     ]
    }
   ],
   "source": [
    "# Model 9\n",
    "# AdaBoost classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_model = AdaBoostClassifier(learning_rate=1)\n",
    "adaboost_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", adaboost_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", adaboost_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, adaboost_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c6db0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chella\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:418: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.8238805970149253\n",
      "Testing Accuracy =  0.8575757575757575\n",
      "Testing F1 Score =  [0.9233279 0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Model 10\n",
    "# Gaussian Process Classifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "# we set the kernel to RBF\n",
    "gauss_process_model = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "gauss_process_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", gauss_process_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", gauss_process_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, gauss_process_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6dbb39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chella\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  1.0\n",
      "Testing Accuracy =  0.8333333333333334\n",
      "Testing F1 Score =  [0.90878939 0.05128205 0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Model 11\n",
    "# Quadratic Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "quadratic_discriminant_model = QuadraticDiscriminantAnalysis()\n",
    "quadratic_discriminant_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", quadratic_discriminant_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", quadratic_discriminant_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, quadratic_discriminant_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa1fc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  1.0\n",
      "Testing Accuracy =  0.8636363636363636\n",
      "Testing F1 Score =  [0.92763158 0.11111111 0.125     ]\n"
     ]
    }
   ],
   "source": [
    "# Model 12\n",
    "# Neural Network in sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# max_iter default is 200\n",
    "# alpha default = 0.0001\n",
    "nn_model = MLPClassifier(alpha=0.01, max_iter=1000)\n",
    "nn_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", nn_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", nn_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, nn_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f589efb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy =  0.9865671641791045\n",
      "Testing Accuracy =  0.8272727272727273\n",
      "Testing F1 Score =  [0.91 0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "# Model 13\n",
    "# Gradient Boost Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gradient_boost_model = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 4)\n",
    "gradient_boost_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy = \", gradient_boost_model.score(x_train, y_train))\n",
    "print(\"Testing Accuracy = \", gradient_boost_model.score(x_test, y_test))\n",
    "\n",
    "# classification F1 score\n",
    "print(\"Testing F1 Score = \", f1_score(y_test, gradient_boost_model.predict(x_test), average=None, labels=[\"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5853f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make training data diverse\n",
    "# Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62f3ec65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEUTRAL'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d63bb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITIVE    552\n",
       "NEUTRAL      71\n",
       "NEGATIVE     47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd1cc5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c1848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
